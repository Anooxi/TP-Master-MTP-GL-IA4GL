{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**DESGENETEZ Charles** 21603540\n",
    "\n",
    "**REITER Maxime** 21604458"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-30 13:25:04.522000: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2021-11-30 13:25:04.522042: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "import codecs\n",
    "import json\n",
    "import time\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from eli5.lime import TextExplainer\n",
    "from sklearn import metrics\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chargement du dataset\n",
    "\n",
    "Fonction permettant l'ouverture d'un jeu de ticket sauvegardé au format json."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(json_path):\n",
    "    raw_data = []\n",
    "    with codecs.open(json_path, \"r\", \"utf-8\") as fin:\n",
    "        raw_data += json.load(fin)\n",
    "    return raw_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fonction de multiplication des titres des tickets\n",
    "\n",
    "Multiplication du titre des tickets par le facteur donné en paramètre. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multiply_title(dataset, factor):\n",
    "    for ticket in dataset:\n",
    "        for i in range(1,factor):\n",
    "            ticket[\"title\"] += \" \" + ticket[\"title\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fonction de binarisation des labels\n",
    "\n",
    "Permet de convertir les labels \"NBUG\" et \"BUG\" en une information binaire 0 ou 1\n",
    "* 0 = NBUG\n",
    "* 1 = BUG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binarization_labels(labels):\n",
    "    return np.ravel(label_binarize(labels, classes=[\"NBUG\",\"BUG\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fonction de récupération du corpus et des étiquettes\n",
    "\n",
    "Cette fonction retourne deux tableaux :\n",
    "* Le premier est un tableau contenant les informations textuelles des tickets (pour chaque ticket, le title est concaténé au body)\n",
    "* Le second tableau contient les labels textuelles associées à chacun des tickets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_corpus_labels(raw_data):\n",
    "# Corpus building.\n",
    "    corpus = []\n",
    "    labels = []\n",
    "    n_bug = 0\n",
    "    for n_file in raw_data:\n",
    "        corpus.append(n_file[\"title\"] + \" \" + n_file[\"body\"])\n",
    "        labels.append(n_file[\"label\"])\n",
    "        if n_file[\"label\"] == \"BUG\":\n",
    "            n_bug += 1\n",
    "    print(f\"{n_bug} BUG / {len(labels)} \\n\")\n",
    "    return corpus, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fonction d'évaluation d'un classifieur avec un train/test split\n",
    "\n",
    "Cette fonction permet l'évaluation d'un classifieur sur la base d'une division du jeu de données en 2 parties :\n",
    "* une partie dédiée à l'entraînement (partie dite _train_)\n",
    "* une partie dédiée au test du classifieur (partie dite _test_)\n",
    "Ici 77% des données du dataset sont destinées à l'entraînement et 33% au test du classifieur. \n",
    "La fonction calcule les mesures F1, rappel et précision. Elle dispose de 4 paramètres :\n",
    "* X : le corpus complet vectorisé\n",
    "* binarized_labels : la liste des labels binarisés\n",
    "* clf : le classifieur à évaluer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_scoring_train_test_split(X,binarized_labels, clf, test_size=33):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, binarized_labels, test_size=test_size, random_state=42)\n",
    "\n",
    "    start_time = time.time()\n",
    "    #scores = cross_val_score(clf, X, binarized_labels, cv=cv, scoring='f1')\n",
    "    print(\"--- Start training ---\",flush=True)\n",
    "    clf.fit(X_train, y_train)\n",
    "    print(\"--- %s seconds for training ---\" % (time.time() - start_time),flush=True)\n",
    "    y_pred = clf.predict(X_test)\n",
    "\n",
    "    recall = metrics.recall_score(y_test, y_pred)\n",
    "    f1 = metrics.f1_score(y_test, y_pred)\n",
    "    precision = metrics.precision_score(y_test, y_pred)\n",
    "\n",
    "    print(\"F1 score train/test: %0.3f\" % f1)\n",
    "    print(\"Recall score train/test: %0.3f\" % recall)\n",
    "    print(\"Precision score train/test: %0.3f\" % precision)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fonction de vectorisation et de calcul des features les plus représentatives\n",
    "Cette fonction prend 4 paramètres en entrée : \n",
    "* corpus : tableau d'éléments textuels extraits avec la fonction <code>get_corpus_labels</code>\n",
    "* labels : tableau de labels binarisés avec la fonction <code>binarization_labels</code>\n",
    "* vectorizer : objet vectorizer pour transformer le corpus \n",
    "* k_best : nombre de features représentatives du corpus à sélectionner à l'aide du chi-deux\n",
    "* print_feature_names : afficher ou non les features sélectionnées par le chi2\n",
    "\n",
    "\n",
    "Vous allez devoir compléter la fonction <code>feature_computing</code>, pour cela :\n",
    "1. Utilisez le vectorizer passé en paramètre afin de transformer les informations textuelles en informatiques mathématiques (vecteurs) utilisables par des classifieurs. Ces vecteurs sont créés à l'aide de la méthode _Term Frequency-Inverse Document Frequency_ ([wiki TF-IDF](https://fr.wikipedia.org/wiki/TF-IDF)) Pour cela référez vous à la fonction <code>fit_transform</code> ([documentation](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html?highlight=tfidf#sklearn.feature_extraction.text.TfidfVectorizer.fit_transform)). Vous affecterez le retour de <code>fit_transform</code> à une variable nommée <code>X</code>. \n",
    "2. La seconde étape consiste à sélectionner les features les plus représentatives du corpus. Un moyen de faire cela est d'utiliser la méthode du Chi-deux. La méthode du chi deux va mesurer la dépendance entre une feature donnée et la classe (BUG ou NBUG) et ainsi vous permettre de sélectionner <code>k</code> features représentatives du corpus. Pour faire cela vous devez créer un objet <code>SelectKBest</code> que vous affecterez à la variable <code>ch2</code>. Vous pouvez vous inspirer de l'exemple donné dans la [documentation](https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.SelectKBest.html?highlight=selectkbest%20fit_transform).\n",
    "3. Utiliser la méthode <code>fit_transform</code> avec en paramètres <code>X</code> et les <code>labels</code>. Affectez le retour de cette méthode à la variable <code>X</code> \n",
    "\n",
    "Si vous souhaitez visualiser les features sélectionnées par le Chi2 vous pouvez passer la variable <code>print_feature_names</code> à True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_computing(corpus, binarized_labels, vectorizer, k_best=30000, print_feature_names=False):\n",
    "    # TF-IDF.\n",
    "    start_time = time.time()\n",
    "    print(\"--- Start feature computing ---\")\n",
    "    #Placer ici la ligne permettant de vectoriser le corpus avec fit_transform\n",
    "    X = vectorizer.fit_transform(corpus, binarized_labels)\n",
    "    print(f\"\\t{X.shape[1]} features.\")\n",
    "\n",
    "    print(\"Extracting %d best features by a chi-squared test\" % k_best)\n",
    "    #Placer ici le code pour extraire les features\n",
    "    ch2 = SelectKBest(chi2, k=k_best)\n",
    "    X = ch2.fit_transform(X, binarized_labels)\n",
    "    \n",
    "    if print_feature_names:  # keep selected feature names.\n",
    "        feature_names = vectorizer.get_feature_names()\n",
    "        feature_names = [feature_names[i] for i in ch2.get_support(indices=True)]\n",
    "        print(feature_names)\n",
    "    \n",
    "    print(\"--- %s seconds for feature computing ---\" % (time.time() - start_time))\n",
    "    return X, vectorizer, ch2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fonction de recherche d'un classifieur optimisé \n",
    "\n",
    "Dans cette fonction nous allons utiliser un algorithme nommé Grid-Search (type brute-force) permettant d'optimiser les paramètres d'un ou plusieurs classifieur(s) puis d'en comparer les performances. Nous allons comparer 5 types de classifieurs disponibles dans Scikit Learn :\n",
    "* Software Vector Machine (SVC ([documentation](https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html?highlight=svc#sklearn.svm.SVC))). Optimisation du paramètre <code>kernel</code> : ['linear','rbf']\n",
    "* LogisticRegression ([documentation](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html?highlight=logisticregression#sklearn.linear_model.LogisticRegression)). Optimisation du paramètre <code>C</code> : [0.5,0.75,1]\n",
    "* MultinomialNB ([documentation](https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.MultinomialNB.html?highlight=multinomialnb#sklearn.naive_bayes.MultinomialNB)). Pas d'optimisation de paramètre. \n",
    "* RandomForestClassifier ([documentation](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html?highlight=randomforestclassifier#sklearn.ensemble.RandomForestClassifier)). Optimisation du paramètre <code>max_depth</code> :[5,10,15]\n",
    "* RidgeClassifier ([documentation](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.RidgeClassifier.html?highlight=ridgeclassifier#sklearn.linear_model.RidgeClassifier)) Optimisation du paramètre <code>alpha</code> : [0.5,0.75,1]\n",
    "\n",
    "**Attention** Certains de ces classifieurs utilisent de l'aléatoire. Il est donc nécessaire de fixer les graines à l'aide du paramètre <code>random_state</code>\n",
    "\n",
    "1. Nous allons utiliser un Pipeline dans lequel nous allons ajouter les dictionnaires contenant les classifieurs et leurs paramètres à ajuster. Pour cela vous allez vous pouvez vous inspirer du code suivant : \n",
    "\n",
    "```python\n",
    "#Créé un Pipeline pseudo vide (workaround pour pouvoir utiliser le pipeline avec plusieurs classifieurs)\n",
    "pipeline = Pipeline([\n",
    "    ('clf', UnClassifieur()),\n",
    "    ])\n",
    "\n",
    "#liste des dictionnaires des différents classifieurs et leurs paramètres à tester\n",
    "parameters = [\n",
    "        {\n",
    "            'clf': [UnClassifieur(random_state=0)],\n",
    "            'clf__myParamClassifieur': ['linear','rbf']\n",
    "        }\n",
    "]\n",
    "grid_search = GridSearchCV(pipeline, parameters, n_jobs=-1)\n",
    "```\n",
    "\n",
    "Dans le code plus haut le Pipeline est initialisé avec un classifieur. C'est un workaround car on ne peut pas créer de Pipeline vide. \n",
    "Nous allons utiliser ce Pipeline avec une liste (variable <code>parameters</code>) de dictionnaires contenant le classifieur à tester et ses paramètres. \n",
    "Dans le dictionnaire présenté plus haut :\n",
    "* <code>'clf'</code> est une liste contenant 1 seul élément, le classifieur à tester.\n",
    "* <code>'clf__myParamClassifieur'</code> permet à l'algorithme de tester le paramètres <myParamClassifieur> du classifieur testé <code>'clf'</code> \n",
    "\n",
    "Pour ajouter les classifieur à tester vous allez vous baser sur le meme principe, à savoir, rajouter des dictionnaires dans <code>parameters</code> avec \n",
    "<code>{'clf' : [mon_classif], 'clf__myPara' : [liste_param_à_tester]}</code>. Vous prendrez la liste des classifieurs/paramètres donnée plus haut dans ce bloc. \n",
    "\n",
    "2. Vous devrez ensuite créer un objet GridSearchCV ([documentation]()) avec en paramètres : <code>pipeline</code>, <code>parameters</code> et <code>n_jobs=-1</code> (pour obtenir un multi-threading sur l'ensemble des coeurs CPU disponibles).\n",
    "3. Vous utiliserez ensuite la méthode fit(X_train,y_train) sur l'objet GridSearch pour lancer la recherche du meilleur couple classifieurs/paramètres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = [\n",
    "    {\n",
    "        'clf': [SVC(random_state=0)],\n",
    "        'clf__kernel': ['linear', 'rbf']\n",
    "    },\n",
    "    {\n",
    "        'clf': [LogisticRegression(random_state=0)], \n",
    "        'clf__C': [0.5,0.75,1]\n",
    "    },\n",
    "    {\n",
    "        'clf': [MultinomialNB()]\n",
    "    },\n",
    "    {\n",
    "        'clf': [RandomForestClassifier(random_state=0)], \n",
    "        'clf__max_depth' :[5,10,15]\n",
    "    },\n",
    "    {\n",
    "        'clf': [RidgeClassifier(random_state=0)],\n",
    "        'clf__alpha': [0.5,0.75,1]\n",
    "    }  \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grid_search_classifiers(X,binarized_labels):\n",
    "    #Séparation du jeu de données en 2. Une partie pour l'entrainement (X_train, y_train) et une partie pour l'évaluation (X_test, y_test)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, binarized_labels, test_size=0.33, random_state=42)\n",
    "\n",
    "    print(\"--- Start grid-search ---\")\n",
    "    start_time = time.time()\n",
    "    \n",
    "    #Placer ici le code avec le pipeline pour le Grid-Search\n",
    "    pipeline = Pipeline([('clf', SVC())])\n",
    "    grid_search = GridSearchCV(pipeline, parameters, n_jobs=-1)\n",
    "    grid_search.fit(X_train, y_train)\n",
    "\n",
    "    best_params = grid_search.best_params_\n",
    "    print(\"Best parameters set found on development set:\")\n",
    "    print()\n",
    "    print(grid_search.best_params_)\n",
    "    print()\n",
    "    print(\"Grid scores on development set:\")\n",
    "    print()\n",
    "    means = grid_search.cv_results_[\"mean_test_score\"]\n",
    "    stds = grid_search.cv_results_[\"std_test_score\"]\n",
    "    for mean, std, params in zip(means, stds, grid_search.cv_results_[\"params\"]):\n",
    "        print(\"%0.3f (+/-%0.03f) for %r\" % (mean, std * 2, params))\n",
    "    print()\n",
    "\n",
    "    print(\"Detailed classification report:\")\n",
    "    print()\n",
    "    print(\"The model is trained on the full development set.\")\n",
    "    print(\"The scores are computed on the full evaluation set.\")\n",
    "    print()\n",
    "    y_true, y_pred = y_test, grid_search.predict(X_test)\n",
    "    print(classification_report(y_true, y_pred))\n",
    "    print()\n",
    "    \n",
    "    print(\"--- %s seconds for grid-search ---\" % (time.time() - start_time))\n",
    "    return best_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bloc principal d'exécution du Grid Search\n",
    "1. Chargement du jeu de données de Herzig et al. avec la méthode <code>load_dataset(\"dataset_herzig_etal.json\")</code>\n",
    "2. Multiplication du titre des tickets du dataset par un facteur 3 via la méthode <code>multiply_title</code>\n",
    "3. Extraction du corpus et des labels via la méthode <code>get_corpus_labels</code>\n",
    "3. Vectorisation à l'aide de TF-IDF. Pour cela, créez un objet Vectorizer à l'aide de <code>TfidfVectorizer(max_df=0.5, min_df=2, ngram_range=(1, 3), sublinear_tf=True, stop_words={'english'})</code>\n",
    "4. Sélection des features représentatives grâce à la méthode <code>feature_computing</code>\n",
    "5. Recherche d'un classifieur via la méthode <code>grid_search_classifiers</code>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1940 BUG / 5591 \n",
      "\n",
      "--- Start feature computing ---\n",
      "\t99349 features.\n",
      "Extracting 30000 best features by a chi-squared test\n",
      "--- 1.610581636428833 seconds for feature computing ---\n",
      "--- Start grid-search ---\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'clf': SVC(random_state=0), 'clf__kernel': 'rbf'}\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.869 (+/-0.025) for {'clf': SVC(random_state=0), 'clf__kernel': 'linear'}\n",
      "0.879 (+/-0.016) for {'clf': SVC(random_state=0), 'clf__kernel': 'rbf'}\n",
      "0.744 (+/-0.024) for {'clf': LogisticRegression(random_state=0), 'clf__C': 0.5}\n",
      "0.773 (+/-0.019) for {'clf': LogisticRegression(random_state=0), 'clf__C': 0.75}\n",
      "0.796 (+/-0.030) for {'clf': LogisticRegression(random_state=0), 'clf__C': 1}\n",
      "0.732 (+/-0.016) for {'clf': MultinomialNB()}\n",
      "0.681 (+/-0.017) for {'clf': RandomForestClassifier(random_state=0), 'clf__max_depth': 5}\n",
      "0.699 (+/-0.017) for {'clf': RandomForestClassifier(random_state=0), 'clf__max_depth': 10}\n",
      "0.713 (+/-0.024) for {'clf': RandomForestClassifier(random_state=0), 'clf__max_depth': 15}\n",
      "0.875 (+/-0.023) for {'clf': RidgeClassifier(random_state=0), 'clf__alpha': 0.5}\n",
      "0.870 (+/-0.023) for {'clf': RidgeClassifier(random_state=0), 'clf__alpha': 0.75}\n",
      "0.863 (+/-0.027) for {'clf': RidgeClassifier(random_state=0), 'clf__alpha': 1}\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.94      0.93      1225\n",
      "           1       0.88      0.81      0.84       621\n",
      "\n",
      "    accuracy                           0.90      1846\n",
      "   macro avg       0.89      0.88      0.88      1846\n",
      "weighted avg       0.90      0.90      0.90      1846\n",
      "\n",
      "\n",
      "--- 15.499622344970703 seconds for grid-search ---\n",
      "Best parameters : \n",
      "{'clf': SVC(random_state=0), 'clf__kernel': 'rbf'}\n"
     ]
    }
   ],
   "source": [
    "#Chargement du jeu de données JSON\n",
    "raw_data = load_dataset(\"dataset_herzig_etal.json\")\n",
    "\n",
    "#Multiplication du titre par un facteur 3 (ajustable)\n",
    "factor = 3\n",
    "multiply_title(raw_data, factor)\n",
    "\n",
    "#Extraction du corpus de tickets et des étiquettes \n",
    "corpus, labels = get_corpus_labels(raw_data)\n",
    "\n",
    "#Transformation des étiquettes textuelles en étiquettes binaires\n",
    "binarized_labels = binarization_labels(labels)\n",
    "\n",
    "#Création d'un vectorizer \n",
    "vectorizer = TfidfVectorizer(max_df=0.5, min_df=2, ngram_range=(1, 3), sublinear_tf=True, stop_words={'english'})\n",
    "\n",
    "#Extraction des features représentatives du corpus de tickets (ici 55000 features les plus réprésentatives)\n",
    "X, vectorizer, ch2 = feature_computing(corpus, binarized_labels, vectorizer)\n",
    "\n",
    "#Recherche du meilleur classifieur\n",
    "best_params = grid_search_classifiers(X, binarized_labels)\n",
    "print(\"Best parameters : \")\n",
    "print(best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_scoring_train_test_split(X,binarized_labels, clf, test_size=33):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, binarized_labels, test_size=test_size, random_state=42)\n",
    "\n",
    "    start_time = time.time()\n",
    "    #scores = cross_val_score(clf, X, binarized_labels, cv=cv, scoring='f1')\n",
    "    print(\"--- Start training ---\",flush=True)\n",
    "    clf.fit(X_train, y_train)\n",
    "    print(\"--- %s seconds for training ---\" % (time.time() - start_time),flush=True)\n",
    "    y_pred = clf.predict(X_test)\n",
    "\n",
    "    recall = metrics.recall_score(y_test, y_pred)\n",
    "    f1 = metrics.f1_score(y_test, y_pred)\n",
    "    precision = metrics.precision_score(y_test, y_pred)\n",
    "\n",
    "    print(\"F1 score train/test: %0.3f\" % f1)\n",
    "    print(\"Recall score train/test: %0.3f\" % recall)\n",
    "    print(\"Precision score train/test: %0.3f\" % precision)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Échantillonage pour trouver un nombre de features optimal\n",
    "\n",
    "Nous allons maintenant échantillonner le nombre de feature afin de trouver un nombre qui permet de donner de bons résultats.  \n",
    "Pour cela nous allons faire varier le nombre de features entre 20000 et 90000.\n",
    "\n",
    "1. Chargement du jeu de données de Herzig et al. avec la méthode <code>load_dataset(\"dataset_herzig_etal.json\")</code>\n",
    "2. Multiplication du titre des tickets du dataset par un facteur 3 via la méthode <code>multiply_title</code>\n",
    "3. Extraction du corpus et des labels via la méthode <code>get_corpus_labels</code>\n",
    "4. Vectorisation à l'aide de TF-IDF. Pour cela, créez un objet Vectorizer à l'aide de <code>TfidfVectorizer(max_df=0.5, min_df=2, ngram_range=(1, 3), sublinear_tf=True, stop_words={'english'})</code>\n",
    "5. Création du classifieur, sélectionner le meilleur couple classifieur/paramètres retourné par Grid-Search précédemment\n",
    "6.Échantillonage du nombre de features par pas de 5000 entre 30000 et 60000, dans la boucle faire :\n",
    "* calcul des features à l'aide de <code>feature_computing</code>\n",
    "* le scoring à l'aide de la méthode <code>make_scoring_train_test_split</code>\n",
    "\n",
    "En cas d'égalité des scores F1 entre différents nombre de features, vous conserverez la valeur du plus grand nombre de features parmi les meilleurs scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1940 BUG / 5591 \n",
      "\n",
      "--- Start feature computing ---\n",
      "\t99349 features.\n",
      "Extracting 30000 best features by a chi-squared test\n",
      "--- 1.5094304084777832 seconds for feature computing ---\n",
      "--- Start training ---\n",
      "--- 8.917691946029663 seconds for training ---\n",
      "F1 score train/test: 0.923\n",
      "Recall score train/test: 0.923\n",
      "Precision score train/test: 0.923\n",
      "\n",
      "--- Start feature computing ---\n",
      "\t99349 features.\n",
      "Extracting 35000 best features by a chi-squared test\n",
      "--- 1.5566682815551758 seconds for feature computing ---\n",
      "--- Start training ---\n",
      "--- 9.719801187515259 seconds for training ---\n",
      "F1 score train/test: 0.923\n",
      "Recall score train/test: 0.923\n",
      "Precision score train/test: 0.923\n",
      "\n",
      "--- Start feature computing ---\n",
      "\t99349 features.\n",
      "Extracting 40000 best features by a chi-squared test\n",
      "--- 1.498232126235962 seconds for feature computing ---\n",
      "--- Start training ---\n",
      "--- 10.405491590499878 seconds for training ---\n",
      "F1 score train/test: 0.923\n",
      "Recall score train/test: 0.923\n",
      "Precision score train/test: 0.923\n",
      "\n",
      "--- Start feature computing ---\n",
      "\t99349 features.\n",
      "Extracting 45000 best features by a chi-squared test\n",
      "--- 1.5187530517578125 seconds for feature computing ---\n",
      "--- Start training ---\n",
      "--- 11.12638545036316 seconds for training ---\n",
      "F1 score train/test: 0.889\n",
      "Recall score train/test: 0.923\n",
      "Precision score train/test: 0.857\n",
      "\n",
      "--- Start feature computing ---\n",
      "\t99349 features.\n",
      "Extracting 50000 best features by a chi-squared test\n",
      "--- 1.5230696201324463 seconds for feature computing ---\n",
      "--- Start training ---\n",
      "--- 11.953898191452026 seconds for training ---\n",
      "F1 score train/test: 0.923\n",
      "Recall score train/test: 0.923\n",
      "Precision score train/test: 0.923\n",
      "\n",
      "--- Start feature computing ---\n",
      "\t99349 features.\n",
      "Extracting 55000 best features by a chi-squared test\n",
      "--- 1.552384853363037 seconds for feature computing ---\n",
      "--- Start training ---\n",
      "--- 12.328519821166992 seconds for training ---\n",
      "F1 score train/test: 0.923\n",
      "Recall score train/test: 0.923\n",
      "Precision score train/test: 0.923\n",
      "\n",
      "--- Start feature computing ---\n",
      "\t99349 features.\n",
      "Extracting 60000 best features by a chi-squared test\n",
      "--- 1.5950708389282227 seconds for feature computing ---\n",
      "--- Start training ---\n",
      "--- 13.412027597427368 seconds for training ---\n",
      "F1 score train/test: 0.923\n",
      "Recall score train/test: 0.923\n",
      "Precision score train/test: 0.923\n",
      "\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "#Chargement du jeu de données JSON\n",
    "raw_data = load_dataset(\"dataset_herzig_etal.json\")\n",
    "\n",
    "#Multiplication du titre par un facteur 3 (ajustable)\n",
    "factor = 3\n",
    "multiply_title(raw_data,factor)\n",
    "\n",
    "#Extraction du corpus de tickets et des étiquettes \n",
    "corpus, labels = get_corpus_labels(raw_data)\n",
    "\n",
    "#Transformation des étiquettes textuelles en étiquettes binaires\n",
    "binarized_labels = binarization_labels(labels)\n",
    "\n",
    "#Création d'un vectorizer Tf-Idf\n",
    "vectorizer = TfidfVectorizer(max_df=0.5, min_df=2, ngram_range=(1, 3), sublinear_tf=True, stop_words={'english'})\n",
    "\n",
    "#Création du classifieur\n",
    "classifier = Pipeline([\n",
    "    ('clf', SVC())\n",
    "])\n",
    "classifier.set_params(**best_params)\n",
    "\n",
    "#Boucle for avec calcul des features et scoring\n",
    "feature_step = 5000\n",
    "feature_min = 30000\n",
    "feature_max = 60000\n",
    "\n",
    "for nb_feat in range (feature_min, feature_max+1, feature_step):\n",
    "    X, vectorizer, ch2 = feature_computing(corpus, binarized_labels, vectorizer, k_best=nb_feat)\n",
    "    make_scoring_train_test_split(X, binarized_labels, classifier)\n",
    "    \n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Création de la matrice de confusion \n",
    "\n",
    "Nous allons maintenant créer la matrice de confusion correspondant à notre classifieur. Cette matrice permet de visualiser graphiquement la qualité de la classification effectuée par notre classifieur. La matrice de confusion recense le nombre de :\n",
    "* vrais positifs (VP)\n",
    "* vrais négatifs (VN)\n",
    "* faux positifs (FP)\n",
    "* faux négatifs (FN)\n",
    "Cette matrice est un indicateur de la qualité de votre classifieur. Plus le nombre de FP et FN est réduit meilleure est la classification. \n",
    "\n",
    "Pour créer cette matrice il vous faut : \n",
    "1. Comme dans les blocs de code précédent charger le jeu, multiplier le titre, extraire le corpus et les labels puis binariser les labels\n",
    "2. Extraire les <code>k</code> meilleures features en fonction de l'échantillonnage fait plus haut (méthode <code>feature_computing</code>)\n",
    "3. Utiliser la meilleure configuration de classifieur calculée avec Grid-Search \n",
    "4. Entraîner ce classifieur à l'aide de la méthode <code>fit</code> avec <code>X_train</code> et <code>y_train</code>\n",
    "5. Faire des prédictions à l'aide de la méthode <code>predict</code> de votre classifieur\n",
    "\n",
    "Pour cela, vous pouvez vous inspirer de l'exemple donné ici : [https://scikit-learn.org/stable/modules/generated/sklearn.metrics.ConfusionMatrixDisplay.html](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.ConfusionMatrixDisplay.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1940 BUG / 5591 \n",
      "\n",
      "--- Start feature computing ---\n",
      "\t99349 features.\n",
      "Extracting 60000 best features by a chi-squared test\n",
      "--- 1.4751856327056885 seconds for feature computing ---\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "#Chargement du jeu de données JSON\n",
    "raw_data = load_dataset(\"dataset_herzig_etal.json\")\n",
    "\n",
    "#Multiplication du titre par un facteur 3 (ajustable)\n",
    "factor = 3\n",
    "multiply_title(raw_data,factor)\n",
    "\n",
    "#Extraction du corpus de tickets et des étiquettes \n",
    "corpus, labels = get_corpus_labels(raw_data)\n",
    "\n",
    "#Transformation des étiquettes textuelles en étiquettes binaires\n",
    "binarized_labels = binarization_labels(labels)\n",
    "\n",
    "#Création du vectorizer TF-IDF et sélection des k-best features avec feature_computing\n",
    "vectorizer = TfidfVectorizer(max_df=0.5, min_df=2, ngram_range=(1, 3), sublinear_tf=True, stop_words={'english'})\n",
    "X, vectorizer, ch2 = feature_computing(corpus, binarized_labels, vectorizer, k_best=feature_max)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, binarized_labels, test_size=0.33, random_state=42)\n",
    "\n",
    "#Création du classifieur, entrainement avec X_train, y_train et prédiction avec X_test\n",
    "classifier = SVC(random_state=0, probability=True)\n",
    "classifier.fit(X_train, y_train)\n",
    "predictions = classifier.predict(X_test)\n",
    "#affichage de la matrice de confusion ConfusionMatrixDisplay\n",
    "cm = confusion_matrix(y_test, predictions, labels=classifier.classes_)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=classifier.classes_)\n",
    "\n",
    "disp.plot()\n",
    "plt.show()\n",
    "\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explicabilité du classifieur\n",
    "\n",
    "Un des défis lié à l'IA et aux algorithmes à trait à leur explicabilité. L'explicabilité se définie comme le fait de pouvoir comprendre les mécanismes internes du classifieur qui fondent une ou plusieurs prédictions. Cette explicabilité peut se faire de manière globale (mécanismes internes du classifieur qui conduisent à la classification) ou de manière locale (mécanisme qui conduisent à la classification d'une instance). \n",
    "\n",
    "Nous allons expliquer la classification de 4 tickets : \n",
    "* 2 tickets sont des faux positifs (indices 3997 et 5098 dans le dataset de tickets)\n",
    "* 2 tickets sont des faux négatifs (indices 2656 et 3479 dans le dataset de tickets)\n",
    "\n",
    "Pour expliquer les mots impactant la classification des tickets nous allons utiliser une méthode d'explication se nommant Lime située dans le package Python [eli5](https://eli5.readthedocs.io/en/latest/index.html). \n",
    "Pour cela vous pouvez vous inspirer de l'exemple donner dans la documentation de eli5 : [https://eli5.readthedocs.io/en/latest/tutorials/black-box-text-classifiers.html#textexplainer](https://eli5.readthedocs.io/en/latest/tutorials/black-box-text-classifiers.html#textexplainer)\n",
    "\n",
    "**Attention** avant d'exécuter le code suivant, veillez à avoir exécuté le code du bloc précédent (code de matrice de confusion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Start feature computing ---\n",
      "\t677997 features.\n",
      "Extracting 60000 best features by a chi-squared test\n",
      "--- 2.6616411209106445 seconds for feature computing ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/e20160002389/.local/lib/python3.8/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <style>\n",
       "    table.eli5-weights tr:hover {\n",
       "        filter: brightness(85%);\n",
       "    }\n",
       "</style>\n",
       "\n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "        \n",
       "\n",
       "    \n",
       "\n",
       "        \n",
       "\n",
       "        \n",
       "    \n",
       "        \n",
       "        \n",
       "    \n",
       "        <p style=\"margin-bottom: 0.5em; margin-top: 0em\">\n",
       "            <b>\n",
       "    \n",
       "        y=0\n",
       "    \n",
       "</b>\n",
       "\n",
       "    \n",
       "    (probability <b>1.000</b>, score <b>-20.203</b>)\n",
       "\n",
       "top features\n",
       "        </p>\n",
       "    \n",
       "    <table class=\"eli5-weights\"\n",
       "           style=\"border-collapse: collapse; border: none; margin-top: 0em; table-layout: auto; margin-bottom: 2em;\">\n",
       "        <thead>\n",
       "        <tr style=\"border: none;\">\n",
       "            \n",
       "                <th style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\" title=\"Feature contribution already accounts for the feature value (for linear models, contribution = weight * feature value), and the sum of feature contributions is equal to the score or, for some classifiers, to the probability. Feature values are shown if &quot;show_feature_values&quot; is True.\">\n",
       "                    Contribution<sup>?</sup>\n",
       "                </th>\n",
       "            \n",
       "            <th style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">Feature</th>\n",
       "            \n",
       "        </tr>\n",
       "        </thead>\n",
       "        <tbody>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 80.00%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +19.990\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        Highlighted in text (sum)\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 99.17%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +0.213\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        &lt;BIAS&gt;\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "        \n",
       "\n",
       "        \n",
       "        \n",
       "\n",
       "        </tbody>\n",
       "    </table>\n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "\n",
       "    <p style=\"margin-bottom: 2.5em; margin-top:-0.5em;\">\n",
       "        <span style=\"background-color: hsl(120, 100.00%, 60.00%); opacity: 1.00\" title=\"0.621\">testfsdirectory</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 80.71%); opacity: 0.87\" title=\"0.219\">fails</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 72.80%); opacity: 0.92\" title=\"0.358\">on</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 66.50%); opacity: 0.96\" title=\"0.482\">windows</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 60.00%); opacity: 1.00\" title=\"0.621\">testfsdirectory</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 80.71%); opacity: 0.87\" title=\"0.219\">fails</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 72.80%); opacity: 0.92\" title=\"0.358\">on</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 66.50%); opacity: 0.96\" title=\"0.482\">windows</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 60.00%); opacity: 1.00\" title=\"0.621\">testfsdirectory</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 80.71%); opacity: 0.87\" title=\"0.219\">fails</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 72.80%); opacity: 0.92\" title=\"0.358\">on</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 66.50%); opacity: 0.96\" title=\"0.482\">windows</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 60.00%); opacity: 1.00\" title=\"0.621\">testfsdirectory</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 80.71%); opacity: 0.87\" title=\"0.219\">fails</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 72.80%); opacity: 0.92\" title=\"0.358\">on</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 66.50%); opacity: 0.96\" title=\"0.482\">windows</span><span style=\"opacity: 0.80\">&quot;</span><span style=\"background-color: hsl(120, 100.00%, 78.09%); opacity: 0.88\" title=\"0.263\">ant</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 77.31%); opacity: 0.89\" title=\"0.276\">test</span><span style=\"opacity: 0.80\">&quot; </span><span style=\"background-color: hsl(120, 100.00%, 78.75%); opacity: 0.88\" title=\"0.251\">generates</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 85.40%); opacity: 0.85\" title=\"0.147\">the</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 91.37%); opacity: 0.82\" title=\"0.069\">following</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 76.59%); opacity: 0.89\" title=\"0.289\">error</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 91.09%); opacity: 0.82\" title=\"0.073\">consistently</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 89.08%); opacity: 0.83\" title=\"0.097\">when</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 78.24%); opacity: 0.88\" title=\"0.260\">run</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 72.80%); opacity: 0.92\" title=\"0.358\">on</span><span style=\"opacity: 0.80\"> a </span><span style=\"background-color: hsl(120, 100.00%, 66.50%); opacity: 0.96\" title=\"0.482\">windows</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 86.00%); opacity: 0.84\" title=\"0.139\">machine</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 85.89%); opacity: 0.85\" title=\"0.140\">even</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 89.08%); opacity: 0.83\" title=\"0.097\">when</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 78.24%); opacity: 0.88\" title=\"0.260\">run</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 79.21%); opacity: 0.88\" title=\"0.244\">as</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 81.72%); opacity: 0.87\" title=\"0.203\">user</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 88.20%); opacity: 0.83\" title=\"0.109\">with</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 83.67%); opacity: 0.86\" title=\"0.173\">administrator</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 84.31%); opacity: 0.85\" title=\"0.163\">privileges</span><span style=\"opacity: 0.80\">\n",
       "\n",
       "    [</span><span style=\"background-color: hsl(120, 100.00%, 89.78%); opacity: 0.83\" title=\"0.088\">junit</span><span style=\"opacity: 0.80\">] </span><span style=\"background-color: hsl(120, 100.00%, 91.20%); opacity: 0.82\" title=\"0.071\">testcase</span><span style=\"opacity: 0.80\">: </span><span style=\"background-color: hsl(120, 100.00%, 66.65%); opacity: 0.95\" title=\"0.479\">testtmpdirisplainfile</span><span style=\"opacity: 0.80\">(</span><span style=\"background-color: hsl(120, 100.00%, 74.19%); opacity: 0.91\" title=\"0.332\">org</span><span style=\"opacity: 0.80\">.</span><span style=\"background-color: hsl(120, 100.00%, 87.96%); opacity: 0.84\" title=\"0.112\">apache</span><span style=\"opacity: 0.80\">.</span><span style=\"background-color: hsl(120, 100.00%, 89.54%); opacity: 0.83\" title=\"0.091\">lucene</span><span style=\"opacity: 0.80\">.</span><span style=\"background-color: hsl(120, 100.00%, 78.62%); opacity: 0.88\" title=\"0.254\">index</span><span style=\"opacity: 0.80\">.</span><span style=\"background-color: hsl(120, 100.00%, 87.95%); opacity: 0.84\" title=\"0.112\">store</span><span style=\"opacity: 0.80\">.</span><span style=\"background-color: hsl(120, 100.00%, 60.00%); opacity: 1.00\" title=\"0.621\">testfsdirectory</span><span style=\"opacity: 0.80\">):     caused </span><span style=\"background-color: hsl(120, 100.00%, 83.98%); opacity: 0.85\" title=\"0.168\">an</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 76.59%); opacity: 0.89\" title=\"0.289\">error</span><span style=\"opacity: 0.80\">\n",
       "    [</span><span style=\"background-color: hsl(120, 100.00%, 89.78%); opacity: 0.83\" title=\"0.088\">junit</span><span style=\"opacity: 0.80\">] </span><span style=\"background-color: hsl(120, 100.00%, 68.45%); opacity: 0.94\" title=\"0.442\">access</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 89.69%); opacity: 0.83\" title=\"0.090\">is</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 88.85%); opacity: 0.83\" title=\"0.100\">denied</span><span style=\"opacity: 0.80\">\n",
       "    [</span><span style=\"background-color: hsl(120, 100.00%, 89.78%); opacity: 0.83\" title=\"0.088\">junit</span><span style=\"opacity: 0.80\">] </span><span style=\"background-color: hsl(0, 100.00%, 82.68%); opacity: 0.86\" title=\"-0.188\">java</span><span style=\"opacity: 0.80\">.</span><span style=\"background-color: hsl(120, 100.00%, 93.21%); opacity: 0.82\" title=\"0.049\">io</span><span style=\"opacity: 0.80\">.ioexception: </span><span style=\"background-color: hsl(120, 100.00%, 68.45%); opacity: 0.94\" title=\"0.442\">access</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 89.69%); opacity: 0.83\" title=\"0.090\">is</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 88.85%); opacity: 0.83\" title=\"0.100\">denied</span><span style=\"opacity: 0.80\">\n",
       "    [</span><span style=\"background-color: hsl(0, 100.00%, 90.52%); opacity: 0.83\" title=\"-0.079\">junit</span><span style=\"opacity: 0.80\">]     </span><span style=\"background-color: hsl(120, 100.00%, 80.21%); opacity: 0.87\" title=\"0.227\">at</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 82.68%); opacity: 0.86\" title=\"-0.188\">java</span><span style=\"opacity: 0.80\">.</span><span style=\"background-color: hsl(120, 100.00%, 93.21%); opacity: 0.82\" title=\"0.049\">io</span><span style=\"opacity: 0.80\">.</span><span style=\"background-color: hsl(120, 100.00%, 71.00%); opacity: 0.93\" title=\"0.392\">winntfilesystem</span><span style=\"opacity: 0.80\">.</span><span style=\"background-color: hsl(120, 100.00%, 76.31%); opacity: 0.89\" title=\"0.294\">createfileexclusively</span><span style=\"opacity: 0.80\">(native </span><span style=\"background-color: hsl(120, 100.00%, 84.93%); opacity: 0.85\" title=\"0.154\">method</span><span style=\"opacity: 0.80\">)\n",
       "    [</span><span style=\"background-color: hsl(0, 100.00%, 90.52%); opacity: 0.83\" title=\"-0.079\">junit</span><span style=\"opacity: 0.80\">]     </span><span style=\"background-color: hsl(120, 100.00%, 80.21%); opacity: 0.87\" title=\"0.227\">at</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 82.68%); opacity: 0.86\" title=\"-0.188\">java</span><span style=\"opacity: 0.80\">.</span><span style=\"background-color: hsl(120, 100.00%, 93.21%); opacity: 0.82\" title=\"0.049\">io</span><span style=\"opacity: 0.80\">.</span><span style=\"background-color: hsl(120, 100.00%, 77.44%); opacity: 0.89\" title=\"0.274\">file</span><span style=\"opacity: 0.80\">.</span><span style=\"background-color: hsl(120, 100.00%, 83.15%); opacity: 0.86\" title=\"0.181\">createnewfile</span><span style=\"opacity: 0.80\">(</span><span style=\"background-color: hsl(120, 100.00%, 77.44%); opacity: 0.89\" title=\"0.274\">file</span><span style=\"opacity: 0.80\">.</span><span style=\"background-color: hsl(120, 100.00%, 95.28%); opacity: 0.81\" title=\"0.029\">java</span><span style=\"opacity: 0.80\">:</span><span style=\"background-color: hsl(120, 100.00%, 76.12%); opacity: 0.90\" title=\"0.297\">828</span><span style=\"opacity: 0.80\">)\n",
       "    [</span><span style=\"background-color: hsl(0, 100.00%, 90.52%); opacity: 0.83\" title=\"-0.079\">junit</span><span style=\"opacity: 0.80\">]     </span><span style=\"background-color: hsl(120, 100.00%, 80.21%); opacity: 0.87\" title=\"0.227\">at</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 74.19%); opacity: 0.91\" title=\"0.332\">org</span><span style=\"opacity: 0.80\">.</span><span style=\"background-color: hsl(120, 100.00%, 87.96%); opacity: 0.84\" title=\"0.112\">apache</span><span style=\"opacity: 0.80\">.</span><span style=\"background-color: hsl(120, 100.00%, 89.54%); opacity: 0.83\" title=\"0.091\">lucene</span><span style=\"opacity: 0.80\">.</span><span style=\"background-color: hsl(120, 100.00%, 78.62%); opacity: 0.88\" title=\"0.254\">index</span><span style=\"opacity: 0.80\">.</span><span style=\"background-color: hsl(120, 100.00%, 87.95%); opacity: 0.84\" title=\"0.112\">store</span><span style=\"opacity: 0.80\">.</span><span style=\"background-color: hsl(120, 100.00%, 60.00%); opacity: 1.00\" title=\"0.621\">testfsdirectory</span><span style=\"opacity: 0.80\">.</span><span style=\"background-color: hsl(120, 100.00%, 66.65%); opacity: 0.95\" title=\"0.479\">testtmpdirisplainfile</span><span style=\"opacity: 0.80\">(</span><span style=\"background-color: hsl(120, 100.00%, 60.00%); opacity: 1.00\" title=\"0.621\">testfsdirectory</span><span style=\"opacity: 0.80\">.</span><span style=\"background-color: hsl(120, 100.00%, 95.28%); opacity: 0.81\" title=\"0.029\">java</span><span style=\"opacity: 0.80\">:</span><span style=\"background-color: hsl(120, 100.00%, 87.54%); opacity: 0.84\" title=\"0.117\">66</span><span style=\"opacity: 0.80\">)</span>\n",
       "    </p>\n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Pipeline et vectorizer nécessaire pour le TextExplainer\n",
    "vectorizer_for_text_explainer = TfidfVectorizer(min_df=1, max_df=1.0,ngram_range=(1, 3), sublinear_tf=True, stop_words={'english'})\n",
    "X, vectorizer, ch2 = feature_computing(corpus, binarized_labels, vectorizer_for_text_explainer, k_best=feature_max)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, binarized_labels, test_size=0.33, random_state=42)\n",
    "\n",
    "pipe = make_pipeline(vectorizer_for_text_explainer, ch2, classifier)\n",
    "\n",
    "#Placez ici le code du text explainer pour le ticket 5098 (ticket_dataset[5098][\"title\"] + ticket_dataset[5098][\"body\"])\n",
    "raw_data[5098][\"title\"] + raw_data[5098][\"body\"]\n",
    "\n",
    "te = TextExplainer(random_state=42)\n",
    "te.fit(doc, pipe.predict_proba)\n",
    "te.show_prediction()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Placez ci-dessous le code du text explainer pour le ticket 3997 (faux positif)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Placez ci-dessous le code du text explainer pour le ticket 2656 (faux négatif)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Placez ci-dessous le code du text explainer pour le ticket 3479 (faux négatif)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "604fa18f26e0fae5824a25e5208a65f3bd7a50a3ed33678f9d75b9937a80ef56"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
